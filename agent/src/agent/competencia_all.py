"""LangGraph single-node graph template.

Returns a predefined response. Replace logic and configuration as needed.
"""

from __future__ import annotations

from dataclasses import dataclass
from typing import Any, Dict, TypedDict

from langchain_core.runnables import RunnableConfig
from langgraph.graph import StateGraph

from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_ollama.llms import OllamaLLM
from langchain_ollama.chat_models import ChatOllama


class Configuration(TypedDict):
    """Configurable parameters for the agent.

    Set these when creating assistants OR when invoking the graph.
    See: https://langchain-ai.github.io/langgraph/cloud/how-tos/configuration_cloud/
    """

    my_configurable_param: str


@dataclass
class State:
    """Input state for the agent.

    Defines the initial structure of incoming data.
    See: https://langchain-ai.github.io/langgraph/concepts/low_level/#state
    """

    essay: str = "example"
    output_1: str = ""
    output_2: str = ""
    output_3: str = ""
    output_4: str = ""
    output_5: str = ""


async def call_model_competencia_1(state: State, config: RunnableConfig) -> State:
    """Process input and returns output.

    Can use runtime configuration to alter behavior.
    """
    configuration = config["configurable"]
    essay = state.essay
    
    model_name_gemma3n_4b = "gemma3n:e2b"

    llm = ChatOllama(model=model_name_gemma3n_4b, 
                    temperature=0.0)
                    #  num_gpu=1)

    system_prompt = """
    Voc√™ √© um assistente que ir√° corrigir reda√ß√µes do ENEM e ajudar os usu√°rios a melhorarem suas habilidades de escrita. Sua tarefa √© avaliar a reda√ß√£o do usu√°rio com base na Compet√™ncia 1 do ENEM.

    üîé A Compet√™ncia 1 avalia se o candidato domina a norma-padr√£o da l√≠ngua portuguesa. Isso inclui: ortografia, acentua√ß√£o, pontua√ß√£o, concord√¢ncia verbal e nominal, reg√™ncia, coloca√ß√£o pronominal e outros aspectos gramaticais. Desvios eventuais n√£o comprometem a nota, mas erros sistem√°ticos ou reincidentes reduzem significativamente a pontua√ß√£o.

    D√™ uma nota de 0 a 200 para essa compet√™ncia e explique o motivo com base nesses crit√©rios. No final, d√™ um feedback construtivo com sugest√£o clara de melhoria.
    """

    prompt = ChatPromptTemplate.from_messages(
            [
                ("system", system_prompt), 
                ("human", "Reda√ß√£o do usu√°rio: \n\n {essay}")
            ]
    )
    
    chain = prompt | llm | StrOutputParser()

    response = await chain.ainvoke({"essay": essay})

    state.output_1 = response

    return state

async def call_model_competencia_2(state: State, config: RunnableConfig) -> State:
    """Process input and returns output.

    Can use runtime configuration to alter behavior.
    """
    configuration = config["configurable"]
    essay = state.essay
    
    model_name_gemma3n_4b = "gemma3n:e2b"

    llm = ChatOllama(model=model_name_gemma3n_4b, 
                    temperature=0.0)
                    #  num_gpu=1)

    system_prompt = """
    Voc√™ √© um assistente que ir√° corrigir reda√ß√µes do ENEM e ajudar os usu√°rios a melhorarem suas habilidades de escrita. Sua tarefa √© avaliar a reda√ß√£o do usu√°rio com base na Compet√™ncia 2 do ENEM.
    
    üîé A Compet√™ncia 2 avalia se o candidato compreendeu o tema proposto, respeitou o g√™nero dissertativo-argumentativo e usou repert√≥rio sociocultural produtivo. A reda√ß√£o deve tratar diretamente do tema e desenvolver argumentos relevantes, com base em conhecimentos das diversas √°reas.

    D√™ uma nota de 0 a 200 para essa compet√™ncia e explique o motivo com base nesses crit√©rios. No final, d√™ um feedback construtivo com sugest√£o clara de melhoria.
    """

    prompt = ChatPromptTemplate.from_messages(
            [
                ("system", system_prompt), 
                ("human", "Reda√ß√£o do usu√°rio: \n\n {essay}")
            ]
    )
    
    chain = prompt | llm | StrOutputParser()

    response = await chain.ainvoke({"essay": essay})

    state.output_2 = response

    return state

async def call_model_competencia_3(state: State, config: RunnableConfig) -> State:
    """Process input and returns output.

    Can use runtime configuration to alter behavior.
    """
    configuration = config["configurable"]
    essay = state.essay
    
    model_name_gemma3n_4b = "gemma3n:e2b"

    llm = ChatOllama(model=model_name_gemma3n_4b, 
                    temperature=0.0)
                    #  num_gpu=1)

    system_prompt = """
    Voc√™ √© um assistente que ir√° corrigir reda√ß√µes do ENEM e ajudar os usu√°rios a melhorarem suas habilidades de escrita. Sua tarefa √© avaliar a reda√ß√£o do usu√°rio com base na Compet√™ncia 3 do ENEM.
    
    üîé A Compet√™ncia 3 avalia a capacidade de o candidato selecionar, relacionar, organizar e interpretar informa√ß√µes, fatos e argumentos para sustentar um ponto de vista. Espera-se progress√£o argumentativa, aprofundamento das ideias e coer√™ncia interna. Argumentos fr√°geis, repetitivos ou desconectados da tese central prejudicam a nota.

    D√™ uma nota de 0 a 200 para essa compet√™ncia e explique o motivo com base nesses crit√©rios. No final, d√™ um feedback construtivo com sugest√£o clara de melhoria.
    """

    prompt = ChatPromptTemplate.from_messages(
            [
                ("system", system_prompt), 
                ("human", "Reda√ß√£o do usu√°rio: \n\n {essay}")
            ]
    )
    
    chain = prompt | llm | StrOutputParser()

    response = await chain.ainvoke({"essay": essay})

    state.output_3 = response
    return state
    
async def call_model_competencia_4(state: State, config: RunnableConfig) -> State:
    """Process input and returns output.

    Can use runtime configuration to alter behavior.
    """
    configuration = config["configurable"]
    essay = state.essay
    
    model_name_gemma3n_4b = "gemma3n:e2b"

    llm = ChatOllama(model=model_name_gemma3n_4b, 
                    temperature=0.0)
                    #  num_gpu=1)

    system_prompt = """
    Voc√™ √© um assistente que ir√° corrigir reda√ß√µes do ENEM e ajudar os usu√°rios a melhorarem suas habilidades de escrita. Sua tarefa √© avaliar a reda√ß√£o do usu√°rio com base na Compet√™ncia 4 do ENEM.

    üîé A Compet√™ncia 4 avalia o dom√≠nio dos mecanismos lingu√≠sticos de coes√£o (conectivos, pronomes, sin√¥nimos) e a coer√™ncia geral do texto. A ideia √© que o texto tenha fluidez, boa paragrafa√ß√£o e sequ√™ncia l√≥gica entre as ideias. Problemas como repeti√ß√µes, saltos argumentativos e uso inadequado de conectivos podem diminuir a nota.

    D√™ uma nota de 0 a 200 para essa compet√™ncia e explique o motivo com base nesses crit√©rios. No final, d√™ um feedback construtivo com sugest√£o clara de melhoria.
    """

    prompt = ChatPromptTemplate.from_messages(
            [
                ("system", system_prompt), 
                ("human", "Reda√ß√£o do usu√°rio: \n\n {essay}")
            ]
    )
    
    chain = prompt | llm | StrOutputParser()

    response = await chain.ainvoke({"essay": essay})

    state.output_4 = response
    return state

async def call_model_competencia_5(state: State, config: RunnableConfig) -> State:
    """Process input and returns output.

    Can use runtime configuration to alter behavior.
    """
    configuration = config["configurable"]
    essay = state.essay
    
    model_name_gemma3n_4b = "gemma3n:e2b"

    llm = ChatOllama(model=model_name_gemma3n_4b, 
                    temperature=0.0)
                    #  num_gpu=1)

    system_prompt = """
    Voc√™ √© um assistente que ir√° corrigir reda√ß√µes do ENEM e ajudar os usu√°rios a melhorarem suas habilidades de escrita. Sua tarefa √© avaliar a reda√ß√£o do usu√°rio com base na Compet√™ncia 5 do ENEM.

    üîé A Compet√™ncia 5 avalia a capacidade do candidato de elaborar uma proposta de interven√ß√£o para o problema apresentado no texto. A proposta deve ser vi√°vel, respeitar os direitos humanos e conter: a√ß√£o, agente, meio de execu√ß√£o, finalidade e detalhamento. Omiss√£o de elementos ou propostas gen√©ricas reduzem a nota.

    D√™ uma nota de 0 a 200 para essa compet√™ncia e explique o motivo com base nesses crit√©rios. No final, d√™ um feedback construtivo com sugest√£o clara de melhoria.
    """

    prompt = ChatPromptTemplate.from_messages(
            [
                ("system", system_prompt), 
                ("human", "Reda√ß√£o do usu√°rio: \n\n {essay}")
            ]
    )
    
    chain = prompt | llm | StrOutputParser()

    response = await chain.ainvoke({"essay": essay})

    state.output_5 = response
    return state

# Define the graph
graph = (
    StateGraph(State, config_schema=Configuration)
    .add_node(call_model_competencia_1)
    .add_edge("__start__", "call_model_competencia_1")
    .add_node(call_model_competencia_2)
    .add_edge("call_model_competencia_1", "call_model_competencia_2")
    .add_node(call_model_competencia_3)
    .add_edge("call_model_competencia_2", "call_model_competencia_3")
    .add_node(call_model_competencia_4)
    .add_edge("call_model_competencia_3", "call_model_competencia_4")
    .add_node(call_model_competencia_5)
    .add_edge("call_model_competencia_4", "call_model_competencia_5")
    .compile(name="ENEM Compet√™ncia all Graph")
)
